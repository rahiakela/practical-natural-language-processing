{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-tf-idf.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMSCK8OiVf49EZ7QIMEAt8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/practical-natural-language-processing/blob/chapter-3-text-representation/4_tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPJvYeCmI7vy",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF: Term frequency–inverse document frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLZUxtltI8hf",
        "colab_type": "text"
      },
      "source": [
        "In all the three approaches we’ve seen so far, **all the words in the text are treated as equally important—there’s no notion of some words in the document being more important than others. TF-IDF, or term frequency–inverse document frequency, addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the corpus.** It’s a commonly used representation scheme for information-retrieval systems, for extracting relevant documents from a corpus for a given text query.\n",
        "\n",
        "The intuition behind TF-IDF is as follows: if a word $w$ appears many times in a document di but does not occur much in the rest of the documents $d_j$ in the corpus, then the word $w$ must be of great importance to the document $d_i$. The importance of $w$ should increase in proportion to its frequency in $d_i$, but at the same time, its importance should decrease in proportion to the word’s frequency in other documents $d_j$ in the corpus. **Mathematically, this is captured using two quantities: TF and IDF. The two are then combined to arrive at the TF-IDF score.**\n",
        "\n",
        "TF (term frequency) measures how often a term or word occurs in a given document. Since different documents in the corpus may be of different lengths, a term may occur more often in a longer document as compared to a shorter document. To normalize these counts, we divide the number of occurrences by the length of the document. TF of a term t in a document d is defined as:\n",
        "\n",
        "`TF(t, d) = (Number of occurrences of term t in document d) / (Total number of terms in the document  d)`\n",
        "\n",
        "IDF (inverse document frequency) measures the importance of the term across a corpus. In computing TF, all terms are given equal importance (weightage). However, it’s a well-known fact that stop words like is, are, am, etc., are not important, even though they occur frequently. To account for such cases, IDF weighs down the terms that are very common across a corpus and weighs up the rare terms. IDF of a term t is calculated as follows:\n",
        "\n",
        "`IDF(t, d) = log(Total number of documents in the corpus) / (Number of documents with term t in them)`\n",
        "\n",
        "\n",
        "**Our toy corpus**\n",
        "\n",
        "|  |  | \n",
        "| --- | --- | \n",
        "| D1 | Dog bites man. |\n",
        "| D2 | Man bites dog. |\n",
        "| D3 | Dog eats meat. |\n",
        "| D4 | Man eats food. |\n",
        "\n",
        "The TF-IDF score is a product of these two terms. Thus, TF-IDF $score = TF * IDF$. Let’s compute TF-IDF scores for our toy corpus. Some terms appear in only one document, some appear in two, while others appear in three documents. The size of our corpus is N=4. Hence, corresponding TF-IDF values for each term are given.\n",
        "\n",
        "| **Word** | **TF Score** | **IFD Score** | **TF-IDF Score** | \n",
        "| --- | --- | --- | --- |\n",
        "| dog | $\\frac{1}{3} = 0.33$ | $log_2(\\frac{4}{3})=0.4114$ | $0.4114*0.33=0.136$ |\n",
        "| bites | $\\frac{1}{2} = 0.17$ | $log_2(\\frac{4}{2})=1$ | $0.1*0.17=0.17$ |\n",
        "| man | $\\frac{1}{3} = 0.33$ | $log_2(\\frac{4}{3})=0.4114$ | $0.4114*0.33=0.136$ |\n",
        "| eats | $\\frac{1}{2} = 0.17$ | $log_2(\\frac{4}{2})=1$ | $0.1*0.17=0.17$ |\n",
        "| meat | $\\frac{1}{12} = 0.083$ | $log_2(\\frac{4}{1})=2$ | $2*0.083=0.17$ |\n",
        "| food | $\\frac{1}{12} = 0.083$ | $log_2(\\frac{4}{1})=2$ | $2*0.083=0.17$ |\n",
        "\n",
        "\n",
        "The TF-IDF vector representation for a document is then simply the TF-IDF score for each term in that document. So, for D1 we get:\n",
        "\n",
        "| **dog** | **bites** | **man** | **eats** | **meat** | **food** |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| 0.136 | 0.17 | 0.136 | 0 | 0 | 0 |\n",
        "\n",
        "Finaly, we will get this matrix for **TF-IDF**.\n",
        "\n",
        "**Documents**\n",
        "\n",
        "|  |  | \n",
        "| --- | --- | \n",
        "| D1 | Dog bites man. |\n",
        "| D2 | Man bites dog. |\n",
        "| D3 | Dog eats meat. |\n",
        "| D4 | Man eats food. |\n",
        "\n",
        "**TF-IDF Matrix**\n",
        "\n",
        "|   | dog | bites | man | eats | meat | food | \n",
        "| --- | --- | --- | --- | --- | --- | --- | \n",
        "| D1 | 0.136 | 0.17 | 0.136 | 0 | 0 | 0 | \n",
        "| D2 | 0.136 | 0.17 | 0.136 | 0 | 0 | 0 | \n",
        "| D3 | 0.136 | 0 | 0 | 0.17 | 0.17 | 0 | \n",
        "| D4 | 0 | 0 | 0.136 | 0.17 | 0 | 0.17 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53SIYnGLLJGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13e4f6c2-39e7-4e31-971c-0c319f1b1c0b"
      },
      "source": [
        "documents = [\n",
        "  \"Dog bites man.\",\n",
        "  \"Man bites dog.\", \n",
        "  \"Dog eats meat.\", \n",
        "  \"Man eats food.\"\n",
        "]\n",
        "\n",
        "processed_docs = [doc.lower().replace('.', '') for doc in documents]\n",
        "processed_docs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4f9IgUuPVFq",
        "colab_type": "text"
      },
      "source": [
        " A simple example of how to get the TF-IDF representation of a document using sklearn's TfidfVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8udT5HgiPSZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# vectorization example with TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaVVKmwPnOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e00d529e-b15d-4e92-9d3d-8789e63cbce7"
      },
      "source": [
        "# IDF for all words in the vocabulary\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
        "print('IDF for all words in the vocabulary: \\n', tfidf.idf_)\n",
        "print('-' * 10)\n",
        "print('All words in the vocabulary:\\n', tfidf.get_feature_names())\n",
        "print('-' * 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IDF for all words in the vocabulary: \n",
            " [1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n",
            "----------\n",
            "All words in the vocabulary:\n",
            " ['bites', 'dog', 'eats', 'food', 'man', 'meat']\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo-WDqzwQDh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "898cedf2-54ab-4bc8-e77c-0d4a49dd11e7"
      },
      "source": [
        "# TFIDF representation for all documents in our corpus\n",
        "print('TFIDF representation for all documents in our corpus: \\n', bow_rep_tfidf.toarray())\n",
        "print('-' * 70)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF representation for all documents in our corpus: \n",
            " [[0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
            " [0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
            " [0.         0.44809973 0.55349232 0.         0.         0.70203482]\n",
            " [0.         0.         0.55349232 0.70203482 0.44809973 0.        ]]\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecvJVscAVbON",
        "colab_type": "text"
      },
      "source": [
        "Let's show the TF-IDF vetcors in dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3NHK4QXVfbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "148b8c81-704d-49e9-9123-da6995281fda"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "bow_indexs = ['D1', 'D2', 'D3', 'D4']\n",
        "pd.DataFrame(bow_rep_tfidf.toarray(), columns=tfidf.get_feature_names(), index=bow_indexs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bites</th>\n",
              "      <th>dog</th>\n",
              "      <th>eats</th>\n",
              "      <th>food</th>\n",
              "      <th>man</th>\n",
              "      <th>meat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D1</th>\n",
              "      <td>0.657829</td>\n",
              "      <td>0.53257</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.53257</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D2</th>\n",
              "      <td>0.657829</td>\n",
              "      <td>0.53257</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.53257</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.44810</td>\n",
              "      <td>0.553492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.702035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.553492</td>\n",
              "      <td>0.702035</td>\n",
              "      <td>0.44810</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       bites      dog      eats      food      man      meat\n",
              "D1  0.657829  0.53257  0.000000  0.000000  0.53257  0.000000\n",
              "D2  0.657829  0.53257  0.000000  0.000000  0.53257  0.000000\n",
              "D3  0.000000  0.44810  0.553492  0.000000  0.00000  0.702035\n",
              "D4  0.000000  0.00000  0.553492  0.702035  0.44810  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDsbGxqQXxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f9377502-6e1c-403a-f04e-366ef8d204e7"
      },
      "source": [
        "# Get the representation using this vocabulary, for a new text\n",
        "temp = tfidf.transform(['dog and man are friends'])\n",
        "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tfidf representation for 'dog and man are friends':\n",
            " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA5Qn3NSRt8O",
        "colab_type": "text"
      },
      "source": [
        "There are several variations of the basic TF-IDF formula that are used in practice. Notice that the TF-IDF scores that we calculated for our corpus might not match the TF-IDF scores given by scikit-learn. This is because scikit-learn uses a slightly modified version of the IDF formula. This stems from provisions to account for possible zero divisions and to not entirely ignore terms that appear in all documents.\n",
        "\n",
        "Similar to BoW, **we can use the TF-IDF vectors to calculate similarity between two texts using a similarity measure like Euclidean distance or cosine similarity. TF-IDF is a commonly used representation in application scenarios such as information retrieval and text classification. However, despite the fact that TF-IDF is better than the vectorization methods we saw earlier in terms of capturing similarities between words, it still suffers from the curse of high dimensionality.**\n",
        "\n",
        "> **Tips**:Even today, TF-IDF continues to be a popular representation scheme for many NLP tasks, especially the initial versions of the solution.\n",
        "\n",
        "If we look back at all the representation schemes we’ve discussed so far, we notice three fundamental drawbacks:\n",
        "\n",
        "* They’re discrete representations—i.e., they treat language units (words, n-grams, etc.) as atomic units. This discreteness hampers their ability to capture relationships between word.\n",
        "\n",
        "* The feature vectors are sparse and high-dimensional representations. The dimensionality increases with the size of the vocabulary, with most values being zero for any vector. This hampers learning capability. Further, high-dimensionality representation makes them computationally inefficient.\n",
        "\n",
        "* They cannot handle OOV words."
      ]
    }
  ]
}