{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-bag-of-words.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMqRDqKurH1nMSEU4KBinpl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/practical-natural-language-processing/blob/chapter-3-text-representation/2_bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPJvYeCmI7vy",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLZUxtltI8hf",
        "colab_type": "text"
      },
      "source": [
        "Bag of words (BoW) is a classical text representation technique that has been used commonly in NLP, especially in text classification problems. The key idea behind it is as follows: represent the text under consideration as a bag (collection) of words while ignoring the order and context. \n",
        "\n",
        "The basic intuition behind it is that it assumes that the text belonging to a given class in the dataset is characterized by a unique set of words. If two text pieces have nearly the same words, then they belong to the same bag (class). Thus, by analyzing the words present in a piece of text, one can identify the class (bag) it belongs to.\n",
        "\n",
        "Similar to one-hot encoding, BoW maps words to unique integer IDs between 1 and $|V|$. Each document in the corpus is then converted into a vector of $|V|$ dimensions where in the ith component of the vector, $i = w_{id}$, is simply the number of times the word w occurs in the document, i.e., we simply score each word in $V$ by their occurrence count in the document.\n",
        "\n",
        "**Our toy corpus**\n",
        "\n",
        "|  |  | \n",
        "| --- | --- | \n",
        "| D1 | Dog bites man. |\n",
        "| D2 | Man bites dog. |\n",
        "| D3 | Dog eats meat. |\n",
        "| D4 | Man eats food. |\n",
        "\n",
        "Thus, for our toy corpus, where the word IDs are `dog = 1, bites = 2, man = 3, meat = 4 , food = 5, eats = 6`, D1 becomes `[1 1 1 0 0 0]`. This is because the first three words in the vocabulary appeared exactly once in D1, and the last three did not appear at all. D4 becomes `[0 0 1 0 1 1]`.\n",
        "\n",
        "Finaly, we will get this matrix for **Bag-of-Words**.\n",
        "\n",
        "**Documents**\n",
        "\n",
        "|  |  | \n",
        "| --- | --- | \n",
        "| D1 | Dog bites man. |\n",
        "| D2 | Man bites dog. |\n",
        "| D3 | Dog eats meat. |\n",
        "| D4 | Man eats food. |\n",
        "\n",
        "**Bag-of-Words Matrix**\n",
        "\n",
        "|   | dog | bites | man | meat | food | eats | \n",
        "| --- | --- | --- | --- | --- | --- | --- |\n",
        "| D1 | 1 | 1 | 1 | 0 | 0 | 0 |\n",
        "| D2 | 1 | 1 | 1 | 0 | 0 | 0 |\n",
        "| D3 |1 | 0 | 0 | 1 | 0 | 1 |\n",
        "| D4 | 0 | 0 | 1 | 0 | 1 | 1 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53SIYnGLLJGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24b9e059-60f7-4ea4-f078-bb426d5b42f8"
      },
      "source": [
        "documents = [\n",
        "  \"Dog bites man.\",\n",
        "  \"Man bites dog.\", \n",
        "  \"Dog eats meat.\", \n",
        "  \"Man eats food.\"\n",
        "]\n",
        "\n",
        "processed_docs = [doc.lower().replace('.', '') for doc in documents]\n",
        "processed_docs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4f9IgUuPVFq",
        "colab_type": "text"
      },
      "source": [
        "Now, let's do the main task of finding bag of words representation. We will use CountVectorizer from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8udT5HgiPSZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhFiPtwrP2Wu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f48351c2-d9d8-4755-dff5-28db07a06e02"
      },
      "source": [
        "print('Our corpus: ', processed_docs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our corpus:  ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaVVKmwPnOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a96a9ae5-3c9a-4d07-e4f6-e6a8714daf4b"
      },
      "source": [
        "# Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "print('Our vocabulary: ', count_vect.vocabulary_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our vocabulary:  {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo-WDqzwQDh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17fc16c3-a4cd-4605-ae7a-fe979b8b483a"
      },
      "source": [
        "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'man bites dog': \", bow_rep[1].toarray())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BoW representation for 'dog bites man':  [[1 1 0 0 1 0]]\n",
            "BoW representation for 'man bites dog':  [[1 1 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c9neU7ENqS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f73db577-6e3f-4af5-ddba-e8e35d0de0d5"
      },
      "source": [
        "bow_rep.toarray()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 0, 1, 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHa2I4wBN8aY",
        "colab_type": "text"
      },
      "source": [
        "Let's show the BOW vetcors in dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlHMTH1lOCMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c5e88619-25ff-4a8b-c7e1-2f9b2aaa781c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "bow_cols = [key for key, _ in count_vect.vocabulary_.items()]\n",
        "bow_indexs = ['D1', 'D2', 'D3', 'D4']\n",
        "pd.DataFrame(bow_rep.toarray(), columns=bow_cols, index=bow_indexs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dog</th>\n",
              "      <th>bites</th>\n",
              "      <th>man</th>\n",
              "      <th>eats</th>\n",
              "      <th>meat</th>\n",
              "      <th>food</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    dog  bites  man  eats  meat  food\n",
              "D1    1      1    0     0     1     0\n",
              "D2    1      1    0     0     1     0\n",
              "D3    0      1    1     0     0     1\n",
              "D4    0      0    1     1     1     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDsbGxqQXxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e50e6818-864b-4d75-f37c-9505807b0192"
      },
      "source": [
        "# Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform(['dog and dog are friends'])\n",
        "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0l9yFAtRLUj",
        "colab_type": "text"
      },
      "source": [
        "In the above code, we represented the text considering the frequency of words into account. **However, sometimes, we don't care about frequency much, but only want to know whether a word appeared in a text or not**. Researchers have shown that such **a representation without considering frequency is useful for sentiment analysis**.\n",
        "\n",
        "That is, each document is represented as a vector of 0s and 1s. We will use the option binary=True in CountVectorizer for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MTKhSlEQmO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb8ec97e-2b74-4c9b-f9b6-5a6a89ec4c1d"
      },
      "source": [
        "# BoW with binary vectors\n",
        "count_vect = CountVectorizer(binary=True)\n",
        "bow_rep_bin = count_vect.fit_transform(processed_docs)\n",
        "temp = count_vect.transform(['dog and dog are friends'])\n",
        "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bow representation for 'dog and dog are friends': [[0 1 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA5Qn3NSRt8O",
        "colab_type": "text"
      },
      "source": [
        "Let’s look at some of the advantages of this encoding:\n",
        "\n",
        "* Like one-hot encoding, BoW is fairly simple to understand and implement.\n",
        "* With this representation, documents having the same words will have their vector representations closer to each other in Euclidean space as compared to documents with completely different words. The distance between D1 and D2 is 0 as compared to the distance between D1 and D4, which is 2. Thus, the vector space resulting from the BoW scheme captures the semantic similarity of documents. So if two documents have similar vocabulary, they’ll be closer to each other in the vector space and vice versa.\n",
        "* We have a fixed-length encoding for any sentence of arbitrary length.\n",
        "\n",
        "However, it has its share of disadvantages, too:\n",
        "\n",
        "* The size of the vector increases with the size of the vocabulary. Thus, sparsity continues to be a problem. One way to control it is by limiting the vocabulary to n number of the most frequent words.\n",
        "* It does not capture the similarity between different words that mean the same thing. Say we have three documents: “I run”, “I ran”, and “I ate”. BoW vectors of all three documents will be equally apart.\n",
        "* This representation does not have any way to handle out of vocabulary words (i.e., new words that were not seen in the corpus that was used to build the vectorizer).\n",
        "* As the name indicates, it is a “bag” of words—word order information is lost in this representation. Both D1 and D2 will have the same representation in this scheme.\n",
        "\n",
        "However, despite these shortcomings, due to its simplicity and ease of implementation, BoW is a commonly used text representation scheme, especially for text classification among other NLP problems."
      ]
    }
  ]
}