{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-named-entity-recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN0yzxFk3237V27CDxWmytK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/practical-natural-language-processing/blob/chapter-5-information-extraction/2_named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wkxG9WsGxOW"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WimeNGEKHB5G"
      },
      "source": [
        "Consider a scenario where the user asks a search query—“Where was Albert Einstein born?”—using Google search.\r\n",
        "\r\n",
        "<img src='https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/5-5.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "To be able to show “Ulm, Germany” for this query, the search engine needs to decipher that Albert Einstein is a person before going on to look for a place of birth. This is an example of NER in action in a real-world application.\r\n",
        "\r\n",
        "**NER refers to the IE task of identifying the entities in a document. Entities are typically names of persons, locations, and organizations, and other specialized strings, such as money expressions, dates, products, names/numbers of laws or articles, and so on. NER is an important step in the pipeline of several NLP applications involving information extraction.**\r\n",
        "\r\n",
        "<img src='https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/5-6.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "As seen in the figure, for a given text, NER is expected to identify person names, locations, dates, and other entities. Different categories of entities identified here are some of the ones commonly used in NER system development.\r\n",
        "\r\n",
        "**NER is a prerequisite for being able to do other IE tasks, such as relation extraction or event extraction**.\r\n",
        "\r\n",
        "NER is also useful in other applications like machine translation, as names\r\n",
        "need not necessarily be translated while translating a sentence. So, clearly, there’s a range of scenarios in NLP projects where NER is a major component. It’s one of the common tasks you’re likely to encounter in NLP projects in industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "334d5niWI4Kb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKh4N4O2dYDR"
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3k9pgNBI5aJ"
      },
      "source": [
        "from nltk.tag import pos_tag\r\n",
        "from sklearn_crfsuite import CRF, metrics\r\n",
        "from sklearn.metrics import make_scorer,confusion_matrix\r\n",
        "from pprint import pprint\r\n",
        "from sklearn.metrics import f1_score,classification_report\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtxDqjHjbKi_",
        "outputId": "2d661273-f36b-4131-f366-437fa71f3115"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOSKkHvBIxVc"
      },
      "source": [
        "## Building an NER System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3-nEGIwIyXT"
      },
      "source": [
        "A simple approach to building an NER system is to maintain a large collection of person/ organization/location names that are the most relevant to our company (e.g., names of all clients, cities in their addresses, etc.); this is typically referred to as a gazetteer. To check whether a given word is a named entity or not, just do a lookup in the gazetteer. If a large number of entities present in our data are covered by a gazetteer, then it’s a great way to start, especially when we don’t have an existing NER system available.\r\n",
        "\r\n",
        "An approach that goes beyond a lookup table is rule-based NER, which can be based on a compiled list of patterns based on word tokens and POS tags.\r\n",
        "\r\n",
        "For example, a pattern “NNP was born,” where “NNP” is the POS tag for a proper noun, indicates that the word that was tagged “NNP” refers to a person. Such rules can be programmed to cover as many cases as possible to build a rule-based NER system. \r\n",
        "\r\n",
        "1. **[Stanford NLP’s RegexNER](https://nlp.stanford.edu/software/regexner.html)**\r\n",
        "2. **[spaCy’s EntityRuler](https://spacy.io/usage/rule-based-matching#entityruler)**\r\n",
        "\r\n",
        "provide functionalities to implement your own rule-based NER.\r\n",
        "\r\n",
        "A more practical approach to NER is to train an ML model, which can predict the\r\n",
        "named entities in unseen text. For each word, a decision has to be made whether or not that word is an entity, and if it is, what type of the entity it is. In many ways, this is very similar to the classification problems.\r\n",
        "\r\n",
        "**The only difference here is that NER is a “sequence labeling” problem.**\r\n",
        "\r\n",
        "The typical classifiers predict labels for texts independent of their surrounding context. Consider a classifier that classifies sentences in a movie review into positive/negative/neutral categories based on their sentiment. This classifier does not (usually) take into account the sentiment of previous (or subsequent) sentences when classifying the current sentence.\r\n",
        "\r\n",
        "**In a sequence classifier, such context is important. A common use case for sequence labeling is POS tagging, where we need information about the parts of speech of surrounding words to estimate the part of speech of the current word. NER is traditionally modeled as a sequence classification problem, where the entity prediction for the current word also depends on the context.**\r\n",
        "\r\n",
        "For example, if the previous word was a person name, there’s a higher probability that the current word is also a person name if it’s a noun (e.g., first and last names).\r\n",
        "\r\n",
        "To illustrate the difference between a normal classifier and a sequence classifier, consider the following sentence: “Washington is a rainy state.” When a normal classifier sees this sentence and has to classify it word by word, it has to make a decision as to whether Washington refers to a person (e.g., George Washington) or the State of Washington without looking at the surrounding words. It’s possible to classify the word “Washington” in this particular sentence as a location only after looking at the context in which it’s being used. It’s for this reason that sequence classifiers are used\r\n",
        "for training NER models.\r\n",
        "\r\n",
        "**Conditional random fields (CRFs) is one of the popular sequence classifier training algorithms.**\r\n",
        "\r\n",
        "The notebook shows how we can use CRFs to train an NER system. We’ll use CONLL-03, a popular dataset used for training NER systems, and an open source sequence labeling library called sklearn-crfsuite, along with a set of simple word- and POS tag–based features, which provide contextual information we need for this task.\r\n",
        "\r\n",
        "To perform sequence classification, we need data in a format that allows us to model the context. Typical training data for NER looks like below, which is a sentence from the CONLL-03 dataset.\r\n",
        "\r\n",
        "\r\n",
        "<img src='https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/5-7.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "The labels in the figure follow what’s known as a BIO notation: B indicates the beginning of an entity; I, inside an entity, indicates when entities comprise more than one word; and O, other, indicates non-entities. Peter Such is a name with two words in the example shown above.\r\n",
        "\r\n",
        "Thus, “Peter” gets tagged as a B-PER, and “Such” gets tagged as an I-PER to indicate that Such is a part of the entity from the previous word. The remaining entities in this example, Essex, Yorkshire, and Headingley, are\r\n",
        "all one-word entities. So, we only see B-ORG and B-LOC as their tags. Once we\r\n",
        "obtain a dataset of sentences annotated in this form and we have a sequence classifier algorithm, how should we train an NER system?\r\n",
        "\r\n",
        "The steps are the same as those for the text classifiers:\r\n",
        "1. Load the dataset\r\n",
        "2. Extract the features\r\n",
        "3. Train the classifier\r\n",
        "4. Evaluate it on a test set\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po6Tg7YqcKMA"
      },
      "source": [
        "### Loading The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC-azFzEcMLd"
      },
      "source": [
        "Loading the dataset is straightforward. This particular dataset is also already split into a train/dev/test set. So, we’ll train the model using the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGRGpa4-gVBn",
        "outputId": "8c49988e-f019-4249-d454-50ff48a3fb47"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "wget https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conlldata/test.txt\r\n",
        "wget https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conlldata/train.txt\r\n",
        "\r\n",
        "mkdir conlldata\r\n",
        "mv *.txt conlldata"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-25 10:47:07--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conlldata/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 376236 (367K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "\rtest.txt              0%[                    ]       0  --.-KB/s               \rtest.txt            100%[===================>] 367.42K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-12-25 10:47:07 (8.87 MB/s) - ‘test.txt’ saved [376236/376236]\n",
            "\n",
            "--2020-12-25 10:47:07--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conlldata/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1655711 (1.6M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "train.txt           100%[===================>]   1.58M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-12-25 10:47:07 (17.1 MB/s) - ‘train.txt’ saved [1655711/1655711]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s7dAiLkcD5h"
      },
      "source": [
        "\"\"\"\r\n",
        "Load the training/testing data. \r\n",
        "input: conll format data, but with only 2 tab separated colums - words and NEtags.\r\n",
        "output: A list where each item is 2 lists.  sentence as a list of tokens, NER tags as a list for each token.\r\n",
        "\"\"\"\r\n",
        "def load__data_conll(file_path):\r\n",
        "  myoutput, words, tags = [], [], []\r\n",
        "  fh = open(file_path)\r\n",
        "  for line in fh:\r\n",
        "    line = line.strip()\r\n",
        "    if \"\\t\" not in line:\r\n",
        "      # Sentence ended.\r\n",
        "      myoutput.append([words, tags])\r\n",
        "      words, tags = [], []\r\n",
        "    else:\r\n",
        "      word, tag = line.split(\"\\t\")\r\n",
        "      words.append(word)\r\n",
        "      tags.append(tag)\r\n",
        "      \r\n",
        "  fh.close()\r\n",
        "  return myoutput"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxjVdx6bRunz"
      },
      "source": [
        "### Extract the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOlgJYKvL-Vi"
      },
      "source": [
        "Let’s look at an example using handcrafted features this time. What features seem intuitively relevant for this task? To identify names of people or places, for example, patterns such as whether the word starts with an uppercase character or whether it’s preceded or succeeded by a verb/ noun, etc., can be used as starting points to train an NER model. \r\n",
        "\r\n",
        "The following function that extracts the previous and next words’ POS tags for a given sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWrM_IteMIfB"
      },
      "source": [
        "\"\"\"\r\n",
        "Get features for all words in the sentence\r\n",
        "Features:\r\n",
        "- word context: a window of 2 words on either side of the current word, and current tag.\r\n",
        "- POS context: a window of 2 POS tags on either side of the current word, and current tag. \r\n",
        "input: sentence as a list of tokens.\r\n",
        "output: list of dictionaries. each dict represents features for that word.\r\n",
        "\"\"\"\r\n",
        "def sent2features(sentence):\r\n",
        "  features = []\r\n",
        "  sent_tags = pos_tag(sentence)   # This format is specific to this POS tagger!\r\n",
        "  for i in range(0, len(sentence)):\r\n",
        "    word = sentence[i]\r\n",
        "    wordfeatures = {}\r\n",
        "    # word features: word, prev 2 words, next 2 words in the sentence.\r\n",
        "    wordfeatures[\"word\"] = word\r\n",
        "\r\n",
        "    if i == 0:\r\n",
        "      wordfeatures[\"prevWord\"] = wordfeatures[\"prevSecondWord\"] = \"<S>\"\r\n",
        "    elif i == 1:\r\n",
        "      wordfeatures[\"prevWord\"] = sentence[0]\r\n",
        "      wordfeatures[\"prevSecondWord\"] = \"</S>\"\r\n",
        "    else:\r\n",
        "      wordfeatures[\"prevWord\"] = sentence[i - 1]\r\n",
        "      wordfeatures[\"prevSecondWord\"] = sentence[i - 2]\r\n",
        "\r\n",
        "    # next two words as features\r\n",
        "    if i == len(sentence) - 2:\r\n",
        "      wordfeatures[\"nextWord\"] = sentence[i + 1]\r\n",
        "      wordfeatures[\"nextNextWord\"] = \"</S>\"\r\n",
        "    elif i == len(sentence) - 1:\r\n",
        "      wordfeatures[\"nextWord\"] = \"</S>\"\r\n",
        "      wordfeatures[\"nextNextWord\"] = \"</S>\"\r\n",
        "    else:\r\n",
        "      wordfeatures[\"nextWord\"] = sentence[i + 1]\r\n",
        "      wordfeatures[\"nextNextWord\"] = sentence[i + 2]\r\n",
        "\r\n",
        "    # POS tag features: current tag, previous and next 2 tags.\r\n",
        "    wordfeatures[\"tag\"] = sent_tags[i][1]\r\n",
        "    if i == 0:\r\n",
        "      wordfeatures[\"prevTag\"] = wordfeatures[\"prevSecondTag\"] = \"<S>\"\r\n",
        "    elif i == 1:\r\n",
        "      wordfeatures[\"prevTag\"] = sent_tags[0][1]\r\n",
        "      wordfeatures[\"prevSecondTag\"] = \"</S>\"\r\n",
        "    else:\r\n",
        "      wordfeatures[\"prevTag\"] = sent_tags[i -1][1]\r\n",
        "      wordfeatures[\"prevSecondTag\"] = sent_tags[i - 2][1]\r\n",
        "\r\n",
        "    # next two words as features\r\n",
        "    if i == len(sentence) - 2:\r\n",
        "      wordfeatures[\"nextTag\"] = sent_tags[i + 1][1]\r\n",
        "      wordfeatures[\"nextNextTag\"] = \"</S>\"\r\n",
        "    elif i == len(sentence) - 1:\r\n",
        "      wordfeatures[\"nextTag\"] = \"</S>\"\r\n",
        "      wordfeatures[\"nextNextTag\"] = \"</S>\"\r\n",
        "    else:\r\n",
        "      wordfeatures[\"nextTag\"] = sent_tags[i + 1][1]\r\n",
        "      wordfeatures[\"nextNextTag\"] = sent_tags[i + 2][1]\r\n",
        "    \r\n",
        "    # That is it! You can add whatever you want!\r\n",
        "    features.append(wordfeatures)\r\n",
        "  return features"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMeYcRc1HXMx"
      },
      "source": [
        "As you can see from the wordfeatures variable, each word is transformed\r\n",
        "into a dictionary of features, and therefore each sentence will look like a list of dictionaries (the variable features), which will be used by the CRF classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93TG87jISuIr"
      },
      "source": [
        "# Extract features from the conll data, after loading it.\r\n",
        "def get_features_conll(conll_data):\r\n",
        "  features = []\r\n",
        "  labels = []\r\n",
        "\r\n",
        "  for sentence in conll_data:\r\n",
        "    features.append(sent2features(sentence[0]))\r\n",
        "    labels.append(sentence[1])\r\n",
        "  return features, labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7zbwapNSi77"
      },
      "source": [
        "### Train the CRF classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjeKRAwiSlXg"
      },
      "source": [
        "The following function is to train an NER system with a CRF model and evaluates the model performance on the development set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J1aa_TlRRFg"
      },
      "source": [
        "# Train a sequence model\r\n",
        "def train_sequence(X_train, Y_train, X_dev, Y_dev):\r\n",
        "  # crf = CRF(algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=50, all_possible_states=True)\r\n",
        "  crf = CRF(algorithm=\"lbfgs\", c1=0.1, c2=10, max_iterations=50)\r\n",
        "\r\n",
        "  # Just to fit on training data\r\n",
        "  crf.fit(X_train, Y_train)\r\n",
        "  labels = list(crf.classes_)\r\n",
        "\r\n",
        "  # testing\r\n",
        "  y_pred = crf.predict(X_dev)\r\n",
        "  sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\r\n",
        "  print(metrics.flat_f1_score(Y_dev, y_pred, average=\"weighted\", labels=labels))\r\n",
        "  print(metrics.flat_classification_report(Y_dev, y_pred, labels=sorted_labels, digits=3))\r\n",
        "  #print(metrics.sequence_accuracy_score(Y_dev, y_pred))\r\n",
        "  get_confusion_matrix(Y_dev, y_pred, labels=sorted_labels)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw9t1gFLX0Nc"
      },
      "source": [
        "### Evaluate it on a test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mrjbUeBXaJp"
      },
      "source": [
        "Confusion Matrix helper function . Source for this function is [here](https://gist.github.com/zachguo/10296432)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86VDlSOYSQlX"
      },
      "source": [
        "def print_cm(cm, labels):\r\n",
        "    print(\"\\n\")\r\n",
        "    \"\"\"pretty print for confusion matrixes\"\"\"\r\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\r\n",
        "    empty_cell = \" \" * columnwidth\r\n",
        "    # Print header\r\n",
        "    print(\"    \" + empty_cell, end=\" \")\r\n",
        "    for label in labels:\r\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\r\n",
        "    print()\r\n",
        "    # Print rows\r\n",
        "    for i, label1 in enumerate(labels):\r\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\r\n",
        "        sum = 0\r\n",
        "        for j in range(len(labels)):\r\n",
        "            cell = \"%{0}.0f\".format(columnwidth) % cm[i, j]\r\n",
        "            sum =  sum + int(cell)\r\n",
        "            print(cell, end=\" \")\r\n",
        "        print(sum) #Prints the total number of instances per cat at the end."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW2MfkxRXjSZ"
      },
      "source": [
        "#python-crfsuite does not have a confusion matrix function, \r\n",
        "#so writing it using sklearn's confusion matrix and print_cm from github\r\n",
        "def get_confusion_matrix(y_true,y_pred,labels):\r\n",
        "    trues,preds = [], []\r\n",
        "    for yseq_true, yseq_pred in zip(y_true, y_pred):\r\n",
        "        trues.extend(yseq_true)\r\n",
        "        preds.extend(yseq_pred)\r\n",
        "    print_cm(confusion_matrix(trues,preds,labels),labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvT2iaErYE4L"
      },
      "source": [
        "### Call all our functions inside the main method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOdyopIiXn0Z",
        "outputId": "3a9f18fe-a2c8-46fd-de1d-64086d7ea327"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "  train_path = \"conlldata/train.txt\"\r\n",
        "  test_path = \"conlldata/test.txt\"\r\n",
        "\r\n",
        "  # 1. Load the dataset\r\n",
        "  conll_train = load__data_conll(train_path)\r\n",
        "  conll_dev = load__data_conll(test_path)\r\n",
        "\r\n",
        "  # 2. Extract the features\r\n",
        "  print(\"Training a Sequence classification model with CRF\")\r\n",
        "  features, labels = get_features_conll(conll_train)\r\n",
        "  devfeatures, devlabels = get_features_conll(conll_dev)\r\n",
        "  #print(features.shape, labels.shape)\r\n",
        "  #print(devfeatures.shape, devlabels.shape)\r\n",
        "\r\n",
        "  # 3. Train the classifier\r\n",
        "  train_sequence(features, labels, devfeatures, devlabels)\r\n",
        "  print(\"Done with sequence model\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training a Sequence classification model with CRF\n",
            "0.9255103670420659\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.973     0.981     0.977     38323\n",
            "       B-LOC      0.694     0.765     0.728      1668\n",
            "       I-LOC      0.738     0.482     0.584       257\n",
            "      B-MISC      0.648     0.309     0.419       702\n",
            "      I-MISC      0.626     0.505     0.559       216\n",
            "       B-ORG      0.670     0.561     0.611      1661\n",
            "       I-ORG      0.551     0.704     0.618       835\n",
            "       B-PER      0.773     0.766     0.769      1617\n",
            "       I-PER      0.819     0.886     0.851      1156\n",
            "\n",
            "    accuracy                          0.928     46435\n",
            "   macro avg      0.721     0.662     0.679     46435\n",
            "weighted avg      0.926     0.928     0.926     46435\n",
            "\n",
            "\n",
            "\n",
            "                O  B-LOC  I-LOC B-MISC I-MISC  B-ORG  I-ORG  B-PER  I-PER \n",
            "         O  37579    118      3     22     32    193    224     88     64 38323\n",
            "     B-LOC    143   1276      1     36      1     95     14     98      4 1668\n",
            "     I-LOC     32      6    124      1      5      0     52      0     37 257\n",
            "    B-MISC    344     48      1    217      2     56     13     19      2 702\n",
            "    I-MISC     58      1      4      4    109      2     29      0      9 216\n",
            "     B-ORG    265    236      0     48      3    932     20    151      6 1661\n",
            "     I-ORG     76     15     18      2     15     21    588      8     92 835\n",
            "     B-PER     86    138      1      5      3     90     44   1238     12 1617\n",
            "     I-PER     26      1     16      0      4      2     83      0   1024 1156\n",
            "Done with sequence model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw1E8PomhjE5"
      },
      "source": [
        "Training this CRF model gave an F1 score of 0.92 on the development data, which is a very good score! \r\n",
        "\r\n",
        "Here, we showed some of the most commonly used features in learning an NER system and used a popular training method and a publicly available dataset.\r\n",
        "\r\n",
        "Clearly, there’s a lot to be done in terms of tuning the model and developing\r\n",
        "(even) better features; this example only serves to illustrate one way of developing an NER model quickly using one particular library. [MITIE](https://github.com/mit-nlp/MITIE) is another such library to train NER systems."
      ]
    }
  ]
}