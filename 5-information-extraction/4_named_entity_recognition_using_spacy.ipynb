{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-named-entity-recognition-using-spacy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+4tIIU8Acxk2Gri8D8Xdh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/practical-natural-language-processing/blob/chapter-5-information-extraction/4_named_entity_recognition_using_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wkxG9WsGxOW"
      },
      "source": [
        "# Named Entity Recognition using spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WimeNGEKHB5G"
      },
      "source": [
        "Consider a scenario where the user asks a search query—“Where was Albert Einstein born?”—using Google search.\r\n",
        "\r\n",
        "<img src='https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/5-5.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "To be able to show “Ulm, Germany” for this query, the search engine needs to decipher that Albert Einstein is a person before going on to look for a place of birth. This is an example of NER in action in a real-world application.\r\n",
        "\r\n",
        "**NER refers to the IE task of identifying the entities in a document. Entities are typically names of persons, locations, and organizations, and other specialized strings, such as money expressions, dates, products, names/numbers of laws or articles, and so on. NER is an important step in the pipeline of several NLP applications involving information extraction.**\r\n",
        "\r\n",
        "<img src='https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/5-6.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "As seen in the figure, for a given text, NER is expected to identify person names, locations, dates, and other entities. Different categories of entities identified here are some of the ones commonly used in NER system development.\r\n",
        "\r\n",
        "**NER is a prerequisite for being able to do other IE tasks, such as relation extraction or event extraction**.\r\n",
        "\r\n",
        "NER is also useful in other applications like machine translation, as names\r\n",
        "need not necessarily be translated while translating a sentence. So, clearly, there’s a range of scenarios in NLP projects where NER is a major component. It’s one of the common tasks you’re likely to encounter in NLP projects in industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOSKkHvBIxVc"
      },
      "source": [
        "## Building an NER System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3-nEGIwIyXT"
      },
      "source": [
        "A simple approach to building an NER system is to maintain a large collection of person/ organization/location names that are the most relevant to our company (e.g., names of all clients, cities in their addresses, etc.); this is typically referred to as a gazetteer. To check whether a given word is a named entity or not, just do a lookup in the gazetteer. If a large number of entities present in our data are covered by a gazetteer, then it’s a great way to start, especially when we don’t have an existing NER system available.\r\n",
        "\r\n",
        "An approach that goes beyond a lookup table is rule-based NER, which can be based on a compiled list of patterns based on word tokens and POS tags.\r\n",
        "\r\n",
        "For example, a pattern “NNP was born,” where “NNP” is the POS tag for a proper noun, indicates that the word that was tagged “NNP” refers to a person. Such rules can be programmed to cover as many cases as possible to build a rule-based NER system. \r\n",
        "\r\n",
        "1. **[Stanford NLP’s RegexNER](https://nlp.stanford.edu/software/regexner.html)**\r\n",
        "2. **[spaCy’s EntityRuler](https://spacy.io/usage/rule-based-matching#entityruler)**\r\n",
        "\r\n",
        "provide functionalities to implement your own rule-based NER.\r\n",
        "\r\n",
        "A more practical approach to NER is to train an ML model, which can predict the\r\n",
        "named entities in unseen text. For each word, a decision has to be made whether or not that word is an entity, and if it is, what type of the entity it is. In many ways, this is very similar to the classification problems.\r\n",
        "\r\n",
        "**The only difference here is that NER is a “sequence labeling” problem.**\r\n",
        "\r\n",
        "The typical classifiers predict labels for texts independent of their surrounding context. Consider a classifier that classifies sentences in a movie review into positive/negative/neutral categories based on their sentiment. This classifier does not (usually) take into account the sentiment of previous (or subsequent) sentences when classifying the current sentence.\r\n",
        "\r\n",
        "**In a sequence classifier, such context is important. A common use case for sequence labeling is POS tagging, where we need information about the parts of speech of surrounding words to estimate the part of speech of the current word. NER is traditionally modeled as a sequence classification problem, where the entity prediction for the current word also depends on the context.**\r\n",
        "\r\n",
        "For example, if the previous word was a person name, there’s a higher probability that the current word is also a person name if it’s a noun (e.g., first and last names).\r\n",
        "\r\n",
        "To illustrate the difference between a normal classifier and a sequence classifier, consider the following sentence: “Washington is a rainy state.” When a normal classifier sees this sentence and has to classify it word by word, it has to make a decision as to whether Washington refers to a person (e.g., George Washington) or the State of Washington without looking at the surrounding words. It’s possible to classify the word “Washington” in this particular sentence as a location only after looking at the context in which it’s being used. It’s for this reason that sequence classifiers are used\r\n",
        "for training NER models.\r\n",
        "\r\n",
        "**Conditional random fields (CRFs) is one of the popular sequence classifier training algorithms.**\r\n",
        "\r\n",
        "Recent advances in NER research either exclude or augment the kind of feature engineering we did in this example with neural network models. [NCRF++](https://github.com/jiesutd/NCRFpp) is another library that can be used to train your own NER using different neural network architectures. \r\n",
        "\r\n",
        "In this notebook, we will take a look at using spaCy commandline to train and evaluate a NER model. We will also compare it with the pretrained NER model in spacy.\r\n",
        "\r\n",
        "Note: we will create multiple folders during this experiment: spacyNER_data\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po6Tg7YqcKMA"
      },
      "source": [
        "### Loading The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC-azFzEcMLd"
      },
      "source": [
        "Loading the dataset is straightforward. This particular dataset is also already split into a train/dev/test set. So, we’ll train the model using the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8YOag-bzJq8"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "mkdir Data\r\n",
        "cd Data\r\n",
        "mkdir conll2003"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGRGpa4-gVBn",
        "outputId": "727bba23-47eb-4ddd-89cb-2eb64fefd711"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "wget https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conll2003/en/train.txt\r\n",
        "wget https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conll2003/en/test.txt\r\n",
        "wget https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conll2003/en/valid.txt\r\n",
        "\r\n",
        "mv *.txt Data/conll2003"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-22 11:14:33--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conll2003/en/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3283420 (3.1M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "\rtrain.txt             0%[                    ]       0  --.-KB/s               \rtrain.txt           100%[===================>]   3.13M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-01-22 11:14:33 (77.0 MB/s) - ‘train.txt’ saved [3283420/3283420]\n",
            "\n",
            "--2021-01-22 11:14:33--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conll2003/en/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748095 (731K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "\rtest.txt              0%[                    ]       0  --.-KB/s               \rtest.txt            100%[===================>] 730.56K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-01-22 11:14:34 (48.3 MB/s) - ‘test.txt’ saved [748095/748095]\n",
            "\n",
            "--2021-01-22 11:14:34--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch5/Data/conll2003/en/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 827443 (808K) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "valid.txt           100%[===================>] 808.05K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-01-22 11:14:34 (52.8 MB/s) - ‘valid.txt’ saved [827443/827443]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7zbwapNSi77"
      },
      "source": [
        "### Converting data to json structures so it can be used by Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tty5A9xxwkW",
        "outputId": "6a9e3ddc-7b9c-4d82-fda0-9773bd9f4c99"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# Read the CONLL data from conll2003 folder, and store the formatted data into a folder spacyNER_data\r\n",
        "mkdir spacyNER_data\r\n",
        "\r\n",
        "# the above two lines create folders if they don't exist. If they do, the output shows a message that it already exists and cannot be created again\r\n",
        "python3 -m spacy convert \"Data/conll2003/train.txt\" spacyNER_data -c ner\r\n",
        "python3 -m spacy convert \"Data/conll2003/test.txt\" spacyNER_data -c ner\r\n",
        "python3 -m spacy convert \"Data/conll2003/valid.txt\" spacyNER_data -c ner"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘spacyNER_data’: File exists\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (14987 documents): spacyNER_data/train.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3684 documents): spacyNER_data/test.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3466 documents): spacyNER_data/valid.json\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxag-_2N0Fgm"
      },
      "source": [
        "**For example, the data before and after running spacy's convert program looks as follows.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J1aa_TlRRFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d344a07e-4766-4a64-fce9-317786addd23"
      },
      "source": [
        "!echo \"BEFORE : (Data/conll2003/train.txt)\"\r\n",
        "!head \"Data/conll2003/train.txt\" -n 11 | tail -n 9\r\n",
        "!echo \"\\nAFTER : (Data/conll2003/train.json)\"\r\n",
        "!head \"spacyNER_data/train.json\" -n 64 | tail -n 49"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEFORE : (Data/conll2003/train.txt)\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\\nAFTER : (Data/conll2003/train.json)\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"id\":1,\n",
            "    \"paragraphs\":[\n",
            "      {\n",
            "        \"sentences\":[\n",
            "          {\n",
            "            \"tokens\":[\n",
            "              {\n",
            "                \"orth\":\"EU\",\n",
            "                \"tag\":\"NNP\",\n",
            "                \"ner\":\"U-ORG\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"rejects\",\n",
            "                \"tag\":\"VBZ\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"German\",\n",
            "                \"tag\":\"JJ\",\n",
            "                \"ner\":\"U-MISC\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"call\",\n",
            "                \"tag\":\"NN\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"to\",\n",
            "                \"tag\":\"TO\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"boycott\",\n",
            "                \"tag\":\"VB\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"British\",\n",
            "                \"tag\":\"JJ\",\n",
            "                \"ner\":\"U-MISC\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"lamb\",\n",
            "                \"tag\":\"NN\",\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVpfsHfS0Xyu"
      },
      "source": [
        "### Training the NER model with Spacy (CLI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYoXoEgX0dLb"
      },
      "source": [
        "All the commandline options can be seen at: https://spacy.io/api/cli#train We are training using the train program in spacy, for English (en), and the results are stored in a folder called \"model\" (created while training). \r\n",
        "\r\n",
        "Our training file is in \"spacyNER_data/train.json\" and the validation file is at: \"spacyNER_data/valid.json\".\r\n",
        "\r\n",
        "-G stands for gpu option. \r\n",
        "-p stands for pipeline, \r\n",
        "\r\n",
        "and it should be followed by a comma separated set of options - in this case, a tagger and an NER are being trained simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86VDlSOYSQlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819cbf40-1b9e-48fc-83c5-a19afd6406b3"
      },
      "source": [
        "!python3 -m spacy train en model spacyNER_data/train.json spacyNER_data/valid.json -G -p tagger,ner"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: model\u001b[0m\n",
            "Training pipeline: ['tagger', 'ner']\n",
            "Starting with blank model 'en'\n",
            "Counting training words (limit=0)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you're using doesn't have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed.\n",
            "  \"__main__\", mod_spec)\n",
            "\n",
            "Itn  Tag Loss    Tag %    NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n",
            "---  ---------  --------  ---------  ------  ------  ------  -------  -------\n",
            "  1  31189.805    94.120  16526.115  84.840  83.726  84.279  100.000    15578\n",
            "  2  16787.411    94.860   7625.323  87.322  86.469  86.893  100.000    15437\n",
            "  3  13609.065    95.196   5282.025  88.016  87.513  87.764  100.000    15512\n",
            "  4  11813.764    95.254   3974.093  88.230  87.681  87.955  100.000    15581\n",
            "  5  10422.525    95.345   3011.552  88.957  88.522  88.739  100.000    15152\n",
            "  6   9633.024    95.479   2636.098  88.970  88.506  88.737  100.000    15658\n",
            "  7   9058.265    95.545   2277.682  89.294  88.708  89.000  100.000    15380\n",
            "  8   8254.984    95.543   2156.480  89.273  88.657  88.964  100.000    15318\n",
            "  9   7913.531    95.566   1895.878  89.226  88.640  88.932  100.000    15223\n",
            " 10   7542.852    95.591   1746.441  89.049  88.405  88.726  100.000    15381\n",
            " 11   7113.108    95.616   1682.250  88.778  88.270  88.523  100.000    15425\n",
            " 12   6809.856    95.647   1459.975  88.874  88.455  88.664  100.000    15501\n",
            " 13   6519.697    95.616   1357.430  88.603  88.186  88.394  100.000    15494\n",
            " 14   6279.887    95.626   1331.317  88.652  88.219  88.435  100.000    15560\n",
            " 15   5912.572    95.647   1230.374  88.817  88.219  88.517  100.000    15300\n",
            " 16   5675.500    95.671   1127.281  88.751  88.169  88.459  100.000    15496\n",
            " 17   5562.825    95.642   1173.337  88.633  88.186  88.409  100.000    15528\n",
            " 18   5296.112    95.642   1062.342  88.804  88.236  88.519  100.000    15568\n",
            " 19   5188.221    95.636   1131.483  88.857  88.304  88.579  100.000    15513\n",
            " 20   4926.619    95.643    971.895  89.186  88.556  88.870  100.000    15354\n",
            " 21   4854.854    95.659    986.736  89.330  88.623  88.975  100.000    15617\n",
            " 22   4673.592    95.642    900.835  89.283  88.607  88.943  100.000    15685\n",
            " 23   4469.260    95.647    931.033  89.169  88.539  88.853  100.000    15738\n",
            " 24   4490.449    95.649    826.264  89.032  88.388  88.709  100.000    15189\n",
            " 25   4209.792    95.653    874.881  89.021  88.421  88.720  100.000    15499\n",
            " 26   4215.763    95.661    889.725  88.934  88.320  88.626  100.000    15096\n",
            " 27   4077.081    95.678    753.684  88.981  88.337  88.658  100.000    15547\n",
            " 28   4085.731    95.657    784.618  88.989  88.405  88.696  100.000    15398\n",
            " 29   3902.622    95.671    800.852  89.135  88.640  88.887  100.000    15647\n",
            " 30   3821.796    95.686    684.845  89.148  88.623  88.885  100.000    15379\n",
            "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
            "model/model-final\n",
            "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
            "model/model-best\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7TRHnB81W4T"
      },
      "source": [
        "Notice how the performance improves with each iteration!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNf4rbz1cam"
      },
      "source": [
        "### Evaluating the model with test data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJ9P2cG1dna"
      },
      "source": [
        "**On Trained model (model/model-best)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW2MfkxRXjSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c42f55-a695-4b93-bb55-7a216c1531c5"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# create a folder to store the output and visualizations. \r\n",
        "mkdir result\r\n",
        "\r\n",
        "python3 -m spacy evaluate model/model-best spacyNER_data/test.json -dp result\r\n",
        "# python -m spacy evaluate model/model-final data/test.txt.json -dp result"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "Time      3.23 s\n",
            "Words     46666 \n",
            "Words/s   14432 \n",
            "TOK       100.00\n",
            "POS       95.21 \n",
            "UAS       0.00  \n",
            "LAS       0.00  \n",
            "NER P     81.72 \n",
            "NER R     82.26 \n",
            "NER F     81.99 \n",
            "Textcat   0.00  \n",
            "\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
            "result\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVgrVAc618UB"
      },
      "source": [
        "A visualization of the entity tagged test data can be seen in result/entities.html folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCHRn1WV8vEC",
        "outputId": "196a4d80-ce36-4ac1-e71e-fa2c6bd238fb"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# create a folder to store the output and visualizations. \r\n",
        "mkdir result\r\n",
        "\r\n",
        "python -m spacy evaluate model/model-final spacyNER_data/test.json -dp result"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘result’: File exists\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "Time      3.30 s\n",
            "Words     46666 \n",
            "Words/s   14157 \n",
            "TOK       100.00\n",
            "POS       95.21 \n",
            "UAS       0.00  \n",
            "LAS       0.00  \n",
            "NER P     81.82 \n",
            "NER R     81.76 \n",
            "NER F     81.79 \n",
            "Textcat   0.00  \n",
            "\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
            "result\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCTXP_5g2EjF"
      },
      "source": [
        "**On spacy's Pretrained NER model (en)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqPe9Dd-PQ3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6203d7-a633-41db-f8b3-af6a131c08b8"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "mkdir pretrained_result\r\n",
        "\r\n",
        "python3 -m spacy evaluate en spacyNER_data/test.json -dp pretrained_result"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "Time      5.73 s\n",
            "Words     46666 \n",
            "Words/s   8144  \n",
            "TOK       100.00\n",
            "POS       86.21 \n",
            "UAS       0.00  \n",
            "LAS       0.00  \n",
            "NER P     6.51  \n",
            "NER R     9.17  \n",
            "NER F     7.62  \n",
            "Textcat   0.00  \n",
            "\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
            "pretrained_result\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvT2iaErYE4L"
      },
      "source": [
        "A visualization of the entity tagged test data can be seen in pretrained_result/entities.html folder."
      ]
    }
  ]
}